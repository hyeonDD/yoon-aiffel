{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292be2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bc8fd",
   "metadata": {},
   "source": [
    "# 1. 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546a71a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/0612_sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/0612_sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec9e48",
   "metadata": {},
   "source": [
    "# 2. 데이터로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0364ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # [[YOUR CODE]]\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbfd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53a2bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] \n",
    "                                         if word in word_to_index \n",
    "                                         else word_to_index['<UNK>'] \n",
    "                                         for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word \n",
    "                                         else '<UNK>' \n",
    "                                         for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f3e7c",
   "metadata": {},
   "source": [
    "# 3. 모델 구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa4864cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "986915ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# 위의 maxlen 을 기준으로 패딩. 앞쪽에 패딩을 붙이자.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d733d34",
   "metadata": {},
   "source": [
    "# 4. 모델 구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd55a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106182, 41)\n",
      "(106182,)\n"
     ]
    }
   ],
   "source": [
    "# 총 146182 건의 데이터 중 40000 건을 검증용으로 사용하자.\n",
    "# validation set 40000건 분리\n",
    "X_val = X_train[:40000]   \n",
    "y_val = y_train[:40000]\n",
    "\n",
    "# validation set을 제외한 나머지 106182건\n",
    "partial_X_train = X_train[40000:]  \n",
    "partial_y_train = y_train[40000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ee36d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어장 크기와 임베딩벡터의 차원을 명시\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0da4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 41, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 41, 64)            49408     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,366,657\n",
      "Trainable params: 1,366,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 1 : 단방향 LSTM 2층으로 쌓기\n",
    "\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_length=maxlen),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbe96a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 41, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 41, 128)           98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,485,953\n",
      "Trainable params: 1,485,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 2 : 쌍방향 LSTM 2층으로 쌓기\n",
    "\n",
    "bi_lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_length=maxlen),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98aa98c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 41, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 16)            14352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,296,305\n",
      "Trainable params: 1,296,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 3 : 1d-CNN\n",
    "\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_length=maxlen),\n",
    "    tf.keras.layers.Conv1D(16, 7, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(5),\n",
    "    tf.keras.layers.Conv1D(16, 7, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d25d69",
   "metadata": {},
   "source": [
    "# 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebff1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 8s 15ms/step - loss: 0.4382 - accuracy: 0.7942 - val_loss: 0.3541 - val_accuracy: 0.8449\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.3264 - accuracy: 0.8630 - val_loss: 0.3373 - val_accuracy: 0.8528\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.2890 - accuracy: 0.8800 - val_loss: 0.3340 - val_accuracy: 0.8558\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.2569 - accuracy: 0.8934 - val_loss: 0.3528 - val_accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.2260 - accuracy: 0.9083 - val_loss: 0.3655 - val_accuracy: 0.8530\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.1993 - accuracy: 0.9200 - val_loss: 0.4047 - val_accuracy: 0.8476\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.1776 - accuracy: 0.9281 - val_loss: 0.4386 - val_accuracy: 0.8485\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.1576 - accuracy: 0.9369 - val_loss: 0.5720 - val_accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.1386 - accuracy: 0.9447 - val_loss: 0.5423 - val_accuracy: 0.8446\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 0.1262 - accuracy: 0.9497 - val_loss: 0.6211 - val_accuracy: 0.8440\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "lstm_history = lstm_model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55ef3404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 11s 29ms/step - loss: 0.4274 - accuracy: 0.7997 - val_loss: 0.3570 - val_accuracy: 0.8457\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.3254 - accuracy: 0.8639 - val_loss: 0.3351 - val_accuracy: 0.8543\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.2867 - accuracy: 0.8808 - val_loss: 0.3563 - val_accuracy: 0.8507\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.2531 - accuracy: 0.8950 - val_loss: 0.3552 - val_accuracy: 0.8536\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.2239 - accuracy: 0.9081 - val_loss: 0.3696 - val_accuracy: 0.8524\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.1974 - accuracy: 0.9189 - val_loss: 0.4248 - val_accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.1764 - accuracy: 0.9274 - val_loss: 0.4584 - val_accuracy: 0.8445\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.1569 - accuracy: 0.9362 - val_loss: 0.5156 - val_accuracy: 0.8467\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.1415 - accuracy: 0.9435 - val_loss: 0.5143 - val_accuracy: 0.8434\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.1265 - accuracy: 0.9498 - val_loss: 0.5916 - val_accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "bi_lstm_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "bi_lstm_history = bi_lstm_model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e272a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 4s 8ms/step - loss: 0.4555 - accuracy: 0.7839 - val_loss: 0.3468 - val_accuracy: 0.8489\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.3038 - accuracy: 0.8728 - val_loss: 0.3300 - val_accuracy: 0.8565\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.2451 - accuracy: 0.9024 - val_loss: 0.3373 - val_accuracy: 0.8577\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1804 - accuracy: 0.9331 - val_loss: 0.3788 - val_accuracy: 0.8503\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1192 - accuracy: 0.9597 - val_loss: 0.4298 - val_accuracy: 0.8448\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0769 - accuracy: 0.9758 - val_loss: 0.5063 - val_accuracy: 0.8416\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0524 - accuracy: 0.9843 - val_loss: 0.5635 - val_accuracy: 0.8422\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9888 - val_loss: 0.6330 - val_accuracy: 0.8367\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.7071 - val_accuracy: 0.8360\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.7799 - val_accuracy: 0.8342\n"
     ]
    }
   ],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "cnn_history = cnn_model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da11918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "208/208 [==============================] - 6s 15ms/step - loss: 0.4340 - accuracy: 0.7989 - val_loss: 0.3510 - val_accuracy: 0.8456\n",
      "Epoch 2/3\n",
      "208/208 [==============================] - 2s 12ms/step - loss: 0.3257 - accuracy: 0.8627 - val_loss: 0.3373 - val_accuracy: 0.8533\n",
      "Epoch 3/3\n",
      "208/208 [==============================] - 2s 12ms/step - loss: 0.2891 - accuracy: 0.8790 - val_loss: 0.3401 - val_accuracy: 0.8546\n",
      "Epoch 1/2\n",
      "208/208 [==============================] - 11s 29ms/step - loss: 0.4269 - accuracy: 0.8002 - val_loss: 0.3490 - val_accuracy: 0.8483\n",
      "Epoch 2/2\n",
      "208/208 [==============================] - 5s 23ms/step - loss: 0.3246 - accuracy: 0.8630 - val_loss: 0.3415 - val_accuracy: 0.8532\n",
      "Epoch 1/2\n",
      "208/208 [==============================] - 2s 7ms/step - loss: 0.4640 - accuracy: 0.7821 - val_loss: 0.3487 - val_accuracy: 0.8473\n",
      "Epoch 2/2\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.3112 - accuracy: 0.8684 - val_loss: 0.3341 - val_accuracy: 0.8544\n",
      "1537/1537 - 4s - loss: 0.3462 - accuracy: 0.8497\n",
      "1537/1537 - 7s - loss: 0.3494 - accuracy: 0.8478\n",
      "1537/1537 - 3s - loss: 0.3425 - accuracy: 0.8517\n",
      "[0.3462374210357666, 0.8497263789176941]\n",
      "[0.34939631819725037, 0.8477734327316284]\n",
      "[0.34254738688468933, 0.8516793251037598]\n"
     ]
    }
   ],
   "source": [
    "# 세 모델의 최적의 에포크는 각각 3, 2, 2 임을 안다.\n",
    "# 이 값들로 다시 fitting\n",
    "\n",
    "lstm_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "bi_lstm_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=3,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "bi_lstm_model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=2,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "cnn_model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=2,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "lstm_results = lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "bi_lstm_results = bi_lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "cnn_results = cnn_model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(lstm_results)\n",
    "print(bi_lstm_results)\n",
    "print(cnn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0936fe4e",
   "metadata": {},
   "source": [
    "# 6. Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97aa7bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# 가장 높은 accuracy 를 준 1D-CNN 모델의 그래프를 시각화해보자.\n",
    "history_dict = cnn_history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f7e46ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')  # \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')  # b는 \"파란 실선\"입니다\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47faa5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c05525",
   "metadata": {},
   "source": [
    "# 7. 학습된 embedding layer 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "861282fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# 첫 레이어 embedding 에, 우리의 모델이 잘 훈련되었다면, 그럴듯한 word-embedding 이 이루어졌을 것이다.\n",
    "# 이를 확인해보자.\n",
    "\n",
    "# 먼저 임베딩된 벡터들을 저장할 디렉토리를 만들고, \n",
    "# 워드벡터를 다루는데 유용한 gensim 패키지버전 확인... 먼저 터미널에서 다음을 입력:\n",
    "# $ mkdir -p ~/aiffel/sentiment_classification/data\n",
    "# $ pip list | grep gensim\n",
    "\n",
    "embedding_layer = cnn_model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "453c525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/0612_sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = cnn_model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8143c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08401033, -0.0889575 , -0.00855551, -0.05298588,  0.04927721,\n",
       "        0.07869884, -0.06560596,  0.01237868,  0.02954806,  0.02870614,\n",
       "       -0.07214991, -0.00983764, -0.04209622,  0.01026887,  0.05460407,\n",
       "        0.06487674,  0.04089818,  0.01329043, -0.05047166,  0.05364168,\n",
       "        0.06288224, -0.01204511, -0.04944069,  0.0185559 ,  0.06141255,\n",
       "       -0.09189028,  0.07322226, -0.03996252,  0.07270923,  0.02646896,\n",
       "        0.03523599,  0.03778783, -0.0637747 ,  0.07805342, -0.06922435,\n",
       "       -0.00540882, -0.03396018, -0.01766626, -0.01310455,  0.0397407 ,\n",
       "       -0.07759216,  0.01162062, -0.04845211,  0.04555965, -0.07468257,\n",
       "       -0.03525211,  0.01424592,  0.00502706,  0.05274574, -0.02539675,\n",
       "        0.00561628, -0.04417329, -0.05209601, -0.02081716, -0.01504637,\n",
       "        0.01039113,  0.05942878,  0.00093929,  0.00046026,  0.03606026,\n",
       "       -0.07417139, -0.06324904,  0.0555009 , -0.05847939, -0.03907322,\n",
       "       -0.00635329, -0.04003576,  0.08075479, -0.06431447, -0.08278201,\n",
       "       -0.04531796,  0.07623059,  0.01352899, -0.01142127, -0.02437604,\n",
       "       -0.02421463,  0.02292977, -0.00878396, -0.06187302,  0.0343819 ,\n",
       "       -0.00280697, -0.06761312,  0.07110736,  0.06298414,  0.00670154,\n",
       "        0.04742975, -0.04258485, -0.04571801, -0.02373643, -0.02897847,\n",
       "        0.10463356, -0.07469174, -0.03662546, -0.09572327,  0.00849287,\n",
       "        0.02330724, -0.00889469,  0.07871031, -0.00802915,  0.03638592,\n",
       "       -0.042806  ,  0.05071609,  0.01506984,  0.06996915,  0.06023672,\n",
       "       -0.06849131, -0.03015645,  0.03609633,  0.07865737, -0.09910496,\n",
       "        0.0528542 ,  0.05068132,  0.00452157, -0.03600818,  0.01621947,\n",
       "       -0.05088541,  0.08781359, -0.02326187, -0.01205743,  0.07189324,\n",
       "       -0.07175898,  0.08438396,  0.00469343,  0.08212207,  0.01164667,\n",
       "       -0.04933076,  0.07282977,  0.07680643], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['사랑']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ac97faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('먹먹', 0.7569153904914856),\n",
       " ('진진', 0.7524681687355042),\n",
       " ('담백', 0.7428818345069885),\n",
       " ('정점', 0.7350031733512878),\n",
       " ('해냈', 0.7236530184745789),\n",
       " ('진한', 0.7234598398208618),\n",
       " ('good', 0.7224597930908203),\n",
       " ('레전드', 0.7203169465065002),\n",
       " ('묵직', 0.7172957062721252),\n",
       " ('입감', 0.7167129516601562)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 워드 벡터가 의미 벡터 공간상에 유의미하게 학습되었는지 확인하는 방법 중에, \n",
    "# 단어를 하나 주고 그와 가장 유사한 단어와 그 유사도를 확인하는 방법이 있습니다. \n",
    "# gensim을 사용하면 아래와 같이 해볼 수 있습니다.\n",
    "\n",
    "word_vectors.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fe7ba",
   "metadata": {},
   "source": [
    "# 8. 한국어 Word2Vec 임베딩을 활용하여 성능 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c08d2738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.2565942 , -0.85421413, -3.6964011 ,  1.0956469 ,  0.599815  ,\n",
       "       -1.9681435 ,  0.32379073, -1.0716053 , -1.1776937 ,  2.0442047 ,\n",
       "        2.2501915 , -2.7868037 , -2.702359  , -0.9775915 , -0.12478333,\n",
       "        0.28235647,  0.77683175, -1.5393747 ,  2.0879042 , -5.444462  ,\n",
       "       -4.931412  ,  0.8532094 ,  0.11118065, -2.743522  ,  0.7902363 ,\n",
       "        0.10469969, -0.56074625,  1.6684421 ,  1.0278419 , -3.8816829 ,\n",
       "       -3.606887  , -3.120771  , -1.2527398 , -0.77196646, -1.0102901 ,\n",
       "        3.331668  ,  0.30032924,  1.2074511 , -1.2813627 ,  2.6281219 ,\n",
       "       -1.4624823 , -1.1354805 ,  0.7605239 ,  2.83577   , -1.199358  ,\n",
       "        3.1347232 ,  4.062026  , -0.23413125,  3.205856  , -0.9567054 ,\n",
       "        0.77167803, -1.4300145 ,  2.9014013 , -3.940087  , -3.234169  ,\n",
       "       -5.5460634 ,  0.6185009 , -0.75793767,  2.1043491 ,  2.350599  ,\n",
       "        2.9313247 , -2.235593  ,  3.2084036 , -5.594638  ,  1.6516634 ,\n",
       "       -0.32628602, -1.8824683 , -1.5573231 , -1.8452163 , -1.4044309 ,\n",
       "        4.872565  , -2.1063929 , -0.32347348,  1.9946551 , -4.0967984 ,\n",
       "       -1.4509655 , -0.09111219, -4.458617  ,  0.06598099, -2.211754  ,\n",
       "        3.0731246 , -0.06910119,  2.2555242 ,  2.0823317 , -0.58695716,\n",
       "       -3.1035714 ,  2.4014452 ,  3.4731216 ,  1.424459  , -4.313935  ,\n",
       "       -3.5665336 , -6.5203366 , -2.1090846 , -3.2797608 ,  0.4331985 ,\n",
       "        1.1721823 ,  1.8870457 , -0.08832774,  5.423067  , -3.8484313 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word2Vec 모델 파일 경로\n",
    "word2vec_file_path = os.getenv('HOME')+'/data/word2vec_ko.model'\n",
    "# Word2Vec 모델 로드\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_file_path)\n",
    "\n",
    "vector = word_vectors.wv['사랑']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a3563dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이별', 0.7626414895057678),\n",
       " ('행복', 0.7550068497657776),\n",
       " ('슬픔', 0.7381505966186523),\n",
       " ('유혹', 0.7238055467605591),\n",
       " ('그리움', 0.7167419195175171),\n",
       " ('추억', 0.7143999338150024),\n",
       " ('꿈', 0.7089294195175171),\n",
       " ('애정', 0.7066588997840881),\n",
       " ('포옹', 0.7034594416618347),\n",
       " ('마음', 0.6972615718841553)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.wv.similar_by_word(\"사랑\") # 위의 영화 리뷰에서나 자주 등장할만한 어휘와는 달리 더 연관성 있어보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "933ab1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector) # 영어 모델의 300 차원에 비하면 작다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77551df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 우리의 모델의 embedding layer 를 Word2Vec 의 것으로 교체하여 다시 학습시켜보자.\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word_vectors.wv:\n",
    "        embedding_matrix[i] = word_vectors.wv[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb1dd51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 35, 16)            11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이제 모델을 구성하고 fine tuning.\n",
    "\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d93df171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "208/208 [==============================] - 2s 7ms/step - loss: 0.2344 - accuracy: 0.9082 - val_loss: 0.3904 - val_accuracy: 0.8428\n",
      "Epoch 2/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.2218 - accuracy: 0.9133 - val_loss: 0.4003 - val_accuracy: 0.8410\n",
      "Epoch 3/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.2110 - accuracy: 0.9187 - val_loss: 0.4101 - val_accuracy: 0.8407\n",
      "Epoch 4/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.2024 - accuracy: 0.9230 - val_loss: 0.4254 - val_accuracy: 0.8396\n",
      "Epoch 5/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1924 - accuracy: 0.9276 - val_loss: 0.4361 - val_accuracy: 0.8377\n",
      "Epoch 6/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1832 - accuracy: 0.9326 - val_loss: 0.4614 - val_accuracy: 0.8332\n",
      "Epoch 7/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1739 - accuracy: 0.9367 - val_loss: 0.4577 - val_accuracy: 0.8356\n",
      "Epoch 8/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1622 - accuracy: 0.9423 - val_loss: 0.4637 - val_accuracy: 0.8360\n",
      "Epoch 9/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1552 - accuracy: 0.9453 - val_loss: 0.4854 - val_accuracy: 0.8348\n",
      "Epoch 10/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1445 - accuracy: 0.9500 - val_loss: 0.5056 - val_accuracy: 0.8349\n",
      "Epoch 11/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1361 - accuracy: 0.9534 - val_loss: 0.5338 - val_accuracy: 0.8319\n",
      "Epoch 12/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1279 - accuracy: 0.9565 - val_loss: 0.5621 - val_accuracy: 0.8319\n",
      "Epoch 13/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1201 - accuracy: 0.9602 - val_loss: 0.5957 - val_accuracy: 0.8286\n",
      "Epoch 14/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1115 - accuracy: 0.9631 - val_loss: 0.6201 - val_accuracy: 0.8303\n",
      "Epoch 15/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1089 - accuracy: 0.9640 - val_loss: 0.6314 - val_accuracy: 0.8315\n",
      "Epoch 16/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.1002 - accuracy: 0.9679 - val_loss: 0.6431 - val_accuracy: 0.8289\n",
      "Epoch 17/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0947 - accuracy: 0.9695 - val_loss: 0.6904 - val_accuracy: 0.8267\n",
      "Epoch 18/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0918 - accuracy: 0.9698 - val_loss: 0.7066 - val_accuracy: 0.8285\n",
      "Epoch 19/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0851 - accuracy: 0.9727 - val_loss: 0.7563 - val_accuracy: 0.8300\n",
      "Epoch 20/20\n",
      "208/208 [==============================] - 1s 6ms/step - loss: 0.0827 - accuracy: 0.9741 - val_loss: 0.7388 - val_accuracy: 0.8289\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c544163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.7654 - accuracy: 0.8246\n",
      "[0.765363872051239, 0.8246434926986694]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf2100",
   "metadata": {},
   "source": [
    "오히려 성능이 떨어졌다... 데이터를 분석해보신 분의 말씀에 따르면 word 의 30% 가량이 UNK 으로 나온다고 한다. 인터넷 은어가 많이 쓰여서 오히려 처음부터 학습시킨 것보다 성능이 떨어지는 것으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
